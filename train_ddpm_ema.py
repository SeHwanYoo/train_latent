import os
import torch
from torch.utils.data import DataLoader
from torch.utils.data.distributed import DistributedSampler
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.distributed import init_process_group, destroy_process_group, broadcast
# from torch.utils.tensorboard import SummaryWriter

# save_image 
from torchvision.utils import save_image

import yaml
import logging

# ê°€ì •: ì•„ë˜ ëª¨ë“ˆë“¤ì€ í˜„ì¬ í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë§ê²Œ ì¡´ì¬í•©ë‹ˆë‹¤.
from core.ldm.util import instantiate_from_config
# from vae import AutoencoderKL
from ddpm import LatentDiffusion
from datasets import ImageDataset

def setup_logging(log_dir, rank):
    """ë¡œê¹… ì„¤ì •. rank 0 í”„ë¡œì„¸ìŠ¤ì—ì„œë§Œ íŒŒì¼ ë° ì½˜ì†”ì— ë¡œê·¸ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    os.makedirs(log_dir, exist_ok=True)
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)

    # rank 0ì—ì„œë§Œ í•¸ë“¤ëŸ¬ë¥¼ ì¶”ê°€í•˜ì—¬ ì¤‘ë³µ ë¡œê¹… ë°©ì§€
    if rank == 0 and not logger.handlers:
        log_path = os.path.join(log_dir, "training.log")
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        
        # íŒŒì¼ í•¸ë“¤ëŸ¬
        file_handler = logging.FileHandler(log_path)
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)
        
        # ìŠ¤íŠ¸ë¦¼(ì½˜ì†”) í•¸ë“¤ëŸ¬
        stream_handler = logging.StreamHandler()
        stream_handler.setFormatter(formatter)
        logger.addHandler(stream_handler)
    elif rank != 0:
        # ë‹¤ë¥¸ rankì˜ í”„ë¡œì„¸ìŠ¤ëŠ” ë¡œê·¸ë¥¼ ì¶œë ¥í•˜ì§€ ì•Šë„ë¡ Null í•¸ë“¤ëŸ¬ ì¶”ê°€
        logger.addHandler(logging.NullHandler())
    return logger

def ddp_setup():
    """torchrun í™˜ê²½ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì‚° í”„ë¡œì„¸ìŠ¤ ê·¸ë£¹ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    init_process_group(backend="nccl")
    # torchrunì´ ì„¤ì •í•œ í™˜ê²½ ë³€ìˆ˜ì—ì„œ rank ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    rank = int(os.environ["RANK"])
    local_rank = int(os.environ["LOCAL_RANK"])
    world_size = int(os.environ["WORLD_SIZE"])
    
    torch.cuda.set_device(local_rank)
    return rank, local_rank, world_size

def ddp_cleanup():
    """í”„ë¡œì„¸ìŠ¤ ê·¸ë£¹ì„ ì •ë¦¬í•©ë‹ˆë‹¤."""
    destroy_process_group()

def save_checkpoint(logger, ckpt_path, model, optimizer, epoch, global_step, best_loss):
    """ì²´í¬í¬ì¸íŠ¸ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
    # DDP ëª¨ë¸ì˜ state_dictë¥¼ ì €ì¥í•  ë•ŒëŠ” .moduleì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
    state = {
        'epoch': epoch,
        'global_step': global_step,
        'model_state_dict': model.module.state_dict(),
        # 'opt_ae_state_dict': opt_ae.state_dict(),
        # 'opt_disc_state_dict': opt_disc.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'best_loss': best_loss,
    }
    torch.save(state, ckpt_path)
    logger.info(f"Checkpoint saved to {ckpt_path}")

def load_checkpoint(logger, ckpt_path, model, optimizer, device):
    """ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    ckpt = torch.load(ckpt_path, map_location=device)
    model.module.load_state_dict(ckpt['model_state_dict'])
    # opt_ae.load_state_dict(ckpt['opt_ae_state_dict'])
    # opt_disc.load_state_dict(ckpt['opt_disc_state_dict'])
    optimizer.load_state_dict(ckpt['optimizer_state_dict']) 
    start_epoch = ckpt['epoch'] + 1
    best_loss = ckpt['best_loss']
    global_step = ckpt['global_step']
    logger.info(f"Checkpoint loaded from {ckpt_path}. Resuming from epoch {start_epoch}.")
    return start_epoch, best_loss, global_step

def main():
    """ë©”ì¸ í•™ìŠµ ë¡œì§"""
    config = yaml.safe_load(open('configs/ddpm_ema.yaml', 'r'))
    
    # DDP ì„¤ì • ë° rank ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    rank, local_rank, world_size = ddp_setup()
    device = local_rank
    
    # writer = None
    # if rank == 0:
        # writer = SummaryWriter(log_dir=config['log_dir'])

    logger = setup_logging(config['log_dir'], rank)
    
    # ëª¨ë¸, ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™”
    model_params = config['model']['params']
    model = LatentDiffusion(
        first_stage_config=model_params['first_stage_config'],
        cond_stage_config=model_params['cond_stage_config'],
        unet_config=model_params['unet_config'],
        num_timesteps_cond=model_params['num_timesteps_cond'],
        cond_stage_key=model_params['cond_stage_key'],
        cond_stage_trainable=model_params['cond_stage_trainable'],
        # concat_mode=model_params['concat_mode'],
        # cond_stage_forward=model_params['cond_stage_forward'],
        conditioning_key=model_params['conditioning_key'],
        # scale_factor=model_params['scale_factor'],
        # scale_by_std=model_params['scale_by_std'],
        
        linear_start=model_params['linear_start'],
        linear_end=model_params['linear_end'],
        # cosine_s=model_params['cosine_s'],
        # given_betas=model_params['given_betas'],
        channels=model_params['channels'],
        image_size=model_params['image_size'],
        
        log_every_t=model_params['log_every_t'],
        
        # use_ema = True
        
    ).to(device)
    
    # loss_fn = instantiate_from_config(model_params['lossconfig']).to(device)
    # opt_ae = torch.optim.Adam(list(model.encoder.parameters()) +
    #                           list(model.decoder.parameters()) +
    #                           list(model.quant_conv.parameters()) +
    #                           list(model.post_quant_conv.parameters()),
    #                           lr=config['model']['base_learning_rate'], betas=(0.5, 0.9))
    
    # opt_disc = torch.optim.Adam(loss_fn.discriminator.parameters(),
    #                             lr=config['model']['base_learning_rate'], betas=(0.5, 0.9))
    
    # ëª¨ë¸ì„ DDPë¡œ ë˜í•‘
    model = DDP(model, device_ids=[device])
    
    # optimizer = torch.optim.AdamW(model.model.parameters(), lr=config['model']['base_learning_rate'])
    inner = model.module
    optimizer = torch.optim.AdamW(inner.model.parameters(),
                                lr=config['model']['base_learning_rate'])
    
    # ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ì„¤ì •
    train_dataset = ImageDataset(config['dataset']['train_dir'],
                                 config['dataset']['txt_dir'],
                                 config['dataset']['resolution'], 
                                 is_label=True
                                 ) 
    test_dataset = ImageDataset(config['dataset']['train_dir'],
                                config['dataset']['txt_dir'],
                                config['dataset']['resolution'], 
                                is_label=True
                                )
    
    # DistributedSampler ì‚¬ìš© ì‹œ, DataLoaderì˜ shuffleì€ Falseì—¬ì•¼ í•©ë‹ˆë‹¤.
    train_sampler = DistributedSampler(train_dataset, num_replicas=world_size, rank=rank, shuffle=True)
    val_sampler = DistributedSampler(test_dataset, num_replicas=world_size, rank=rank, shuffle=False)
    
    train_loader = DataLoader(train_dataset, batch_size=config['dataset']['batch_size'], shuffle=False, sampler=train_sampler, num_workers=4, pin_memory=True)
    val_loader = DataLoader(test_dataset, batch_size=config['dataset']['batch_size'], shuffle=False, sampler=val_sampler, num_workers=4, pin_memory=True)
    
    start_epoch = 0
    best_loss = float('inf')
    global_step = 0
    
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ (rank 0ì—ì„œë§Œ ì‹¤í–‰í•´ë„ ë˜ì§€ë§Œ, ëª¨ë“  í”„ë¡œì„¸ìŠ¤ê°€ ë™ì¼í•œ ìƒíƒœì—ì„œ ì‹œì‘í•˜ë„ë¡ ì—¬ê¸°ì„œ ë¡œë“œ)
    ckpt_dir = config['model']['ckpt_dir']
    os.makedirs(ckpt_dir, exist_ok=True)
    last_ckpt_path = os.path.join(ckpt_dir, "best.pth")
    if os.path.exists(last_ckpt_path):
        start_epoch, best_loss, global_step = load_checkpoint(logger, last_ckpt_path, model, optimizer, device)
    
    os.makedirs(config['model']['samples_dir'], exist_ok=True)
    
    patience = 10 
    epochs_no_improve = 0
        
    # í•™ìŠµ ë£¨í”„
    for epoch in range(start_epoch, config['model']['epochs']):
        model.train()
        train_sampler.set_epoch(epoch) # ë§¤ ì—í­ë§ˆë‹¤ ìƒ˜í”ŒëŸ¬ì˜ ì‹œë“œë¥¼ ë³€ê²½í•˜ì—¬ ë°ì´í„° ì…”í”Œë§
        
        for i, (images, labels) in enumerate(train_loader):
            images = images.to(device)
            labels = labels.to(device)
            
            with torch.no_grad():
                encoder_posterior = model.module.encode_first_stage(images)
                z = model.module.get_first_stage_encoding(encoder_posterior).detach()
                
            # c = model.module.get_learned_conditioning(labels)
            # c = model.module.get_learned_conditioning({"class_label": labels.long()})
            
            optimizer.zero_grad()
            # loss, log_dict = model(z, c) 
            loss, log_dict = model(z, {"class_label": labels.long()}) 
            loss.backward() 
            optimizer.step() 

            if rank == 0 and i % 100 == 0:
                logger.info(f"Epoch: {epoch} | Batch: {i}/{len(train_loader)} | Loss: {loss.item():.6f}")
                # for key, val in log_dict.items():
                #     writer.add_scalar(key, val, global_step)
                for key, val in log_dict.items():
                    logger.info(f"{key}: {val:.6f}")
            
            global_step += 1
            
        torch.distributed.barrier()
        
        if rank == 0:
            model.eval() # í‰ê°€ ëª¨ë“œë¡œ ë³€ê²½

            # --- 1. ìƒ˜í”Œ ì´ë¯¸ì§€ ì €ì¥ (ë§¤ ì—í­ë§ˆë‹¤ ìˆ˜í–‰) ---
            with torch.no_grad():
                # ê²€ì¦ ë°ì´í„°ì…‹ì—ì„œ ê³ ì •ëœ ìƒ˜í”Œ ë°°ì¹˜ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
                # val_batch = next(iter(val_loader))
                # val_images = val_batch["image"].to(device)
                # val_labels = val_batch["class_label"].to(device)
                for images, labels in val_loader:
                    val_images = images.to(device)
                    val_labels = labels.to(device)
                    break

                # VAEë¥¼ í†µí•´ ì›ë³¸ ì´ë¯¸ì§€ì˜ ì ì¬ ë²¡í„° zë¥¼ ì–»ìŠµë‹ˆë‹¤.
                encoder_posterior = model.module.encode_first_stage(val_images)
                z = model.module.get_first_stage_encoding(encoder_posterior)
                
                # ì»¨ë””ì…˜ cë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.
                # c = model.module.get_learned_conditioning(val_labels)
                
                # LDM ìƒ˜í”Œë§ì„ í†µí•´ ì ì¬ ë²¡í„° ë³µì›
                # (ëª¨ë¸ì— `sample` ë©”ì„œë“œê°€ êµ¬í˜„ë˜ì–´ ìˆë‹¤ê³  ê°€ì •)
                # samples_z, _ = model.module.sample(cond={"class_label": val_labels.long()}, batch_size=val_images.shape[0], return_intermediates=True)
                
                # cond_emb = model.module.get_learned_conditioning(val_labels.long())
                cond_dict  = {"class_label": val_labels.long()}          # â‘  ë”•ì…”ë„ˆë¦¬ë¡œ ë˜í•‘
                cond_emb   = model.module.get_learned_conditioning(cond_dict) 
                samples_z, _ = model.module.sample(
                    cond=cond_emb,                       # ğŸ”¸ ë”•ì…”ë„ˆë¦¬ NO
                    batch_size=val_images.size(0),
                    return_intermediates=True)
                
                # ë³µì›ëœ ì ì¬ ë²¡í„°ë¥¼ VAE ë””ì½”ë”ë¡œ ì´ë¯¸ì§€í™”
                x_samples = model.module.decode_first_stage(samples_z)

                # ì›ë³¸ ì´ë¯¸ì§€ì™€ ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ë¹„êµí•˜ê¸° ìœ„í•´ ì €ì¥
                comparison_grid = torch.cat([val_images[:8], x_samples[:8]])
                save_image(comparison_grid, os.path.join(config['model']['samples_dir'], f"epoch_{epoch:04d}.png"), nrow=8, normalize=True, value_range=(-1, 1))
                logger.info(f"Epoch {epoch:03d} | Sample images saved.")

            # --- 2. ê²€ì¦ ë° ìµœê³  ëª¨ë¸ ì €ì¥ (5 ì—í­ë§ˆë‹¤ ìˆ˜í–‰) ---
            # if (epoch + 1) % 5 == 0:
            #     total_val_loss = 0.0
            #     with torch.no_grad():
            #         # for batch in val_loader:
            #         #     images = batch["image"].to(device)
            #         #     labels = batch["class_label"].to(device)
            #         for images, labels in val_loader:
            #             images = images.to(device)
            #             labels = labels.to(device)
                        
            #             encoder_posterior = model.module.encode_first_stage(images)
            #             z = model.module.get_first_stage_encoding(encoder_posterior)
            #             c = model.module.get_learned_conditioning(labels)
                        
            #             loss, _ = model(z, c)
            #             total_val_loss += loss.item()

            #     avg_val_loss = total_val_loss / len(val_loader)
            #     logger.info(f"Epoch {epoch:03d} | --- Validation --- | Avg Loss: {avg_val_loss:.6f}")
                # writer.add_scalar("validation/avg_loss", avg_val_loss, epoch)
            if (epoch + 1) % 5 == 0:
                total = 0.0
                with torch.no_grad():
                    for images, labels in val_loader:          # â† tuple
                        images = images.to(device)
                        labels = labels.to(device)

                        z = model.module.get_first_stage_encoding(
                                model.module.encode_first_stage(images))
                        cond = {"class_label": labels.long()}
                        loss, _ = model(z, cond)
                        total += loss.item()

                avg_val_loss = total / len(val_loader)
                logger.info(f"Epoch {epoch:03d} | val/avg_loss: {avg_val_loss:.6f}")

                # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
                # is_best = avg_val_loss < best_loss
                # if is_best:
                #     best_loss = avg_val_loss
                #     logger.info(f"New best validation loss: {best_loss:.6f}. Saving best model...")
                #     save_checkpoint(logger, os.path.join(ckpt_dir, "best.pth"), model, optimizer, epoch, global_step, best_loss)
                if avg_val_loss < best_loss:
                    best_loss = avg_val_loss
                    epochs_no_improve = 0 # ì¹´ìš´í„° ë¦¬ì…‹
                    logger.info(f"New best validation loss: {best_loss:.6f}. Saving best model...")
                    
                    save_checkpoint(logger, os.path.join(ckpt_dir, "best.pth"), model, optimizer, epoch, global_step, best_loss)
                else:
                    epochs_no_improve += 1
                    logger.info(f"Validation loss did not improve for {epochs_no_improve} validation runs.")
            

            # --- 3. ìµœì‹  ìƒíƒœ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (ë§¤ ì—í­ë§ˆë‹¤ ìˆ˜í–‰) ---
            save_checkpoint(logger, os.path.join(ckpt_dir, "last.pth"), model, optimizer, epoch, global_step, best_loss)

        stop_signal = torch.tensor(0.0, device=device)
        if rank == 0 and epochs_no_improve >= patience:
            stop_signal.fill_(1.0)
            logger.info(f"Early stopping triggered after {patience} validation runs without improvement.")
        
        # ì‹ í˜¸ë¥¼ ëª¨ë“  í”„ë¡œì„¸ìŠ¤ì— ë¸Œë¡œë“œìºìŠ¤íŠ¸
        broadcast(stop_signal, src=0)
        
        # ì‹ í˜¸ë¥¼ ë°›ìœ¼ë©´ ë£¨í”„ ì¤‘ë‹¨
        if stop_signal.item() == 1:
            break

        torch.distributed.barrier()
        
        # ë‹¤ìŒ ì—í­ì„ ìœ„í•´ ëª¨ë“  í”„ë¡œì„¸ìŠ¤ê°€ ë™ê¸°í™”ë  ë•Œê¹Œì§€ ëŒ€ê¸°
        torch.distributed.barrier()
        
    # if rank == 0:
    #     writer.close()

    ddp_cleanup()

if __name__ == '__main__':
    main()